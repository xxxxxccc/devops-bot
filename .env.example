# DevOps Bot Configuration
# Copy this file to .env.local and fill in your values

# ============================================
# Project Configuration
# ============================================

# Target project path (the codebase AI will work on)
TARGET_PROJECT_PATH=/path/to/your/project

# ============================================
# Webhook Server Configuration
# ============================================

# Server port
WEBHOOK_PORT=3200

# Authentication secret (required for API calls)
WEBHOOK_SECRET=dev-secret

# ============================================
# AI Provider Configuration
# ============================================

# AI provider: anthropic | openai (default: anthropic)
# OpenAI mode also works with any OpenAI-compatible API (DeepSeek, Groq, Together, etc.)
# AI_PROVIDER=anthropic

# AI API key (required)
# For Anthropic: get from https://console.anthropic.com/
# For OpenAI:    get from https://platform.openai.com/api-keys
AI_API_KEY=your-api-key-here

# Custom base URL (optional, for OpenAI-compatible endpoints)
# Examples:
#   DeepSeek: https://api.deepseek.com/v1
#   Groq:     https://api.groq.com/openai/v1
#   Together: https://api.together.xyz/v1
# AI_BASE_URL=

# Task AI model (Layer 2 - intelligent, expensive)
# TASK_MODEL=claude-opus-4-5-20251101

# Dispatcher AI model (Layer 1 - fast, cheap)
# DISPATCHER_MODEL=claude-sonnet-4-5-20250929

# ============================================
# IM Platform Configuration
# ============================================

# IM platform: feishu | slack (default: feishu)
# IM_PLATFORM=feishu

# --- Feishu (Lark) ---
# WebSocket mode - no public IP needed
#
# Setup:
#   1. Create app: https://open.feishu.cn/app
#   2. Enable event: Events & Callbacks → Event Config → Use Long Connection
#   3. Add event: im.message.receive_v1
#   4. Add permissions: im:message, im:message:send_as_bot, im:resource, contact:user.base:readonly

FEISHU_APP_ID=
FEISHU_APP_SECRET=

# --- Slack ---
# Socket Mode - no public URL needed
#
# Setup:
#   1. Create app: https://api.slack.com/apps
#   2. Enable Socket Mode
#   3. Subscribe to events: message.channels, message.groups, message.im, app_mention
#   4. Add scopes: chat:write, files:read, users:read

# SLACK_BOT_TOKEN=xoxb-...
# SLACK_APP_TOKEN=xapp-...

# ============================================
# Memory Configuration
# ============================================

# Extract memories every N messages in a conversation
# MEMORY_EXTRACT_THRESHOLD=5

# Model used for memory extraction (cheap model recommended)
# MEMORY_MODEL=claude-haiku-4-5-20251001

# ============================================
# Jira/Atlassian Integration (Optional)
# ============================================

# Jira configuration
# JIRA_URL=https://your-company.atlassian.net
# JIRA_USERNAME=your-email@company.com
# JIRA_API_TOKEN=your-jira-api-token

# Confluence configuration (shares token with Jira)
# CONFLUENCE_URL=https://your-company.atlassian.net/wiki
# CONFLUENCE_USERNAME=your-email@company.com
# CONFLUENCE_API_TOKEN=your-jira-api-token

# ============================================
# Figma Integration (Optional)
# ============================================

# Figma Personal Access Token
# Get it from: Figma → Settings → Personal access tokens → Generate new token
# FIGMA_API_KEY=figd_xxxxxxxxxxxx

# ============================================
# Embedding / Vector Search (Optional)
# ============================================

# Local embedding (recommended, no cost):
#   Run `devops-bot setup-embedding` to install node-llama-cpp
#   and pre-download the embeddinggemma-300M model (~300MB).
#   Or it auto-downloads on first search.

# OpenAI embedding fallback (if no local model available):
# OPENAI_API_KEY=sk-xxxxx

# ============================================
# Sandbox / Task Isolation (Optional)
# ============================================

# Base directory for git worktree sandboxes (default: /tmp/devops-bot-sandbox)
# SANDBOX_BASE_DIR=/tmp/devops-bot-sandbox

# Automatically create PR/MR after task completion (default: true)
# AUTO_CREATE_PR=true

# Create PRs as draft (default: true, recommended)
# PR_DRAFT=true

# Git platform token for auto-creating PRs/MRs (recommended)
# If not set, falls back to CLI tools (gh / glab) which must be installed and authenticated.
#
# GitHub: https://github.com/settings/tokens?type=beta
#   Fine-grained token → select repo → Pull requests: Read and write
#   (git push uses your SSH key / credential helper — no Contents permission needed)
# GITHUB_TOKEN=github_pat_xxxx
#
# GitLab (including self-hosted): User Settings → Access Tokens → api scope
# GITLAB_TOKEN=glpat-xxxx

# Custom setup command after worktree creation (overrides auto-detection)
# Use for projects with non-standard dependency setup (iOS, Android, monorepos, etc.)
# Examples:
#   SANDBOX_SETUP_COMMAND="pod install"
#   SANDBOX_SETUP_COMMAND="./gradlew dependencies"
#   SANDBOX_SETUP_COMMAND="make deps"
# SANDBOX_SETUP_COMMAND=

# ============================================
# Optional
# ============================================

# Log level (debug/info/warn/error)
LOG_LEVEL=info
